nohup: 忽略输入
{'n_cpu': 0, 'device': device(type='cuda', index=3), 'batch_size_test': 40, 'batch_size': 2, 'lr': 0.001, 'weight_decay': 0, 'display_interval': 250, 'num_epochs': 50, 'early_stopping': True, 'patience': 5, 'gradient_clipping': True, 'clipping_threshold': 1.0, 'input_dim': 8, 'output_dim': 2, 'input_length': 12, 'output_length': 24, 'input_gap': 1, 'pred_shift': 24, 'model_i': 0, 'kernel_size': (3, 3), 'bias': True, 'hidden_dim_1': (128, 128, 128, 128), 'd_attn_1': 64, 'ssr_decay_rate': 8e-05, 'hidden_dim_2': (32, 32, 32, 32), 'd_attn_2': 16, 'hidden_dim_3': (32, 32, 32, 32), 'd_attn_3': 16, 'hidden_dim_4': (32, 32, 32, 32), 'd_attn_4': 16, 'hidden_dim_5': (32, 32, 32, 32), 'd_attn_5': 16, 'use_hc': 1, 'time': 'hybrid', 'save_last': 0}

reading data
(1692, 24, 48, 21, 4) (432, 24, 48, 1, 4)
(1692, 21, 3) (432, 1, 3)
processing training set
(151, 38, 24, 48, 21, 4)
(3171, 38, 24, 48, 4)
(3171, 38, 3)
predData.shape= (3171, 38, 2, 24, 48)
{'sst': (3171, 38, 24, 48, 6), 'nino target': (3171, 38, 3)}
processing eval set
(395, 38, 24, 48, 1, 4)
(395, 38, 24, 48, 4)
(395, 38, 3)
predData.shape= (395, 38, 2, 24, 48)
{'sst': (395, 38, 24, 48, 6), 'nino target': (395, 38, 3)}
Total params num: 7040258
*****************Finish Parameter****************
loading train dataloader
loading eval dataloader

epoch: 1
batch training loss: 936.82, 88.22, score: -19.8759, ssr ratio: 0.9999
batch training loss: 384.71, 31.35, score: 94.3414, ssr ratio: 0.9799
batch training loss: 485.07, 40.27, score: 96.5252, ssr ratio: 0.9599
batch training loss: 400.90, 18.69, score: 87.5010, ssr ratio: 0.9399
batch training loss: 465.01, 21.24, score: 106.1055, ssr ratio: 0.9199
batch training loss: 395.95, 20.72, score: 106.4589, ssr ratio: 0.8999
batch training loss: 398.92, 18.66, score: 105.6061, ssr ratio: 0.8799
tensor([0.9350, 0.8861, 0.8434, 0.8135, 0.7887, 0.7544, 0.7132, 0.6749, 0.6440,
        0.6190, 0.6038, 0.6002, 0.6055, 0.6124, 0.6151, 0.6079, 0.5875, 0.5588,
        0.5370, 0.5276, 0.5220, 0.5202, 0.5233, 0.5256], device='cuda:3')
epoch eval loss:
sst: 614.70, nino: 124.72, sc: 46.6812
eval score is improved from -inf to 46.68116, saving model

epoch: 2
batch training loss: 479.86, 18.76, score: 73.6713, ssr ratio: 0.8730
batch training loss: 402.39, 31.04, score: 88.7678, ssr ratio: 0.8530
batch training loss: 391.97, 13.57, score: 107.2288, ssr ratio: 0.8330
batch training loss: 420.55, 19.15, score: 77.5451, ssr ratio: 0.8130
batch training loss: 434.11, 47.09, score: 102.2338, ssr ratio: 0.7930
batch training loss: 435.81, 33.23, score: 71.0379, ssr ratio: 0.7730
batch training loss: 482.93, 21.53, score: 105.7245, ssr ratio: 0.7530
tensor([0.9346, 0.8830, 0.8323, 0.7860, 0.7455, 0.7086, 0.6747, 0.6444, 0.6181,
        0.5943, 0.5759, 0.5665, 0.5675, 0.5736, 0.5765, 0.5711, 0.5543, 0.5290,
        0.5044, 0.4860, 0.4678, 0.4505, 0.4359, 0.4267], device='cuda:3')
epoch eval loss:
sst: 650.56, nino: 134.38, sc: 40.9832
Epoch 00002: reducing learning rate of group 0 to 3.0000e-04.
eval score is not improved for 1 epoch

epoch: 3
batch training loss: 465.10, 17.33, score: 89.8117, ssr ratio: 0.7462
batch training loss: 406.78, 17.05, score: 87.2950, ssr ratio: 0.7262
batch training loss: 434.02, 19.68, score: 62.3644, ssr ratio: 0.7062
batch training loss: 418.28, 31.78, score: 104.4213, ssr ratio: 0.6862
batch training loss: 409.45, 12.92, score: 89.9795, ssr ratio: 0.6662
batch training loss: 387.54, 26.05, score: 105.0150, ssr ratio: 0.6462
batch training loss: 414.83, 23.53, score: 106.1221, ssr ratio: 0.6262
tensor([0.9388, 0.8899, 0.8455, 0.8077, 0.7740, 0.7405, 0.7091, 0.6818, 0.6568,
        0.6303, 0.6070, 0.5920, 0.5866, 0.5850, 0.5803, 0.5676, 0.5437, 0.5134,
        0.4881, 0.4745, 0.4658, 0.4606, 0.4584, 0.4581], device='cuda:3')
epoch eval loss:
sst: 592.42, nino: 127.43, sc: 42.6741
Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.
eval score is not improved for 2 epoch

epoch: 4
batch training loss: 402.18, 19.77, score: 97.5357, ssr ratio: 0.6193
batch training loss: 418.65, 14.38, score: 99.0586, ssr ratio: 0.5993
batch training loss: 429.37, 20.22, score: 105.6613, ssr ratio: 0.5793
batch training loss: 410.53, 20.40, score: 95.3693, ssr ratio: 0.5593
batch training loss: 412.25, 32.22, score: 105.2496, ssr ratio: 0.5393
batch training loss: 400.05, 18.63, score: 106.0493, ssr ratio: 0.5193
batch training loss: 459.68, 33.72, score: 101.9391, ssr ratio: 0.4993
tensor([0.9460, 0.9062, 0.8716, 0.8438, 0.8194, 0.7931, 0.7653, 0.7367, 0.7068,
        0.6749, 0.6492, 0.6349, 0.6325, 0.6338, 0.6314, 0.6182, 0.5917, 0.5578,
        0.5302, 0.5163, 0.5085, 0.5059, 0.5079, 0.5106], device='cuda:3')
epoch eval loss:
sst: 586.15, nino: 124.27, sc: 48.0704
eval score is improved from 46.68116 to 48.07036, saving model

epoch: 5
batch training loss: 458.89, 32.77, score: 103.8869, ssr ratio: 0.4924
batch training loss: 443.92, 26.63, score: 105.0618, ssr ratio: 0.4724
batch training loss: 445.48, 31.26, score: 94.7801, ssr ratio: 0.4524
batch training loss: 443.39, 26.97, score: 83.2689, ssr ratio: 0.4324
batch training loss: 521.24, 26.73, score: 93.8284, ssr ratio: 0.4124
batch training loss: 493.87, 26.18, score: 92.4863, ssr ratio: 0.3924
batch training loss: 409.54, 44.01, score: 102.8836, ssr ratio: 0.3724
tensor([0.9459, 0.9057, 0.8701, 0.8411, 0.8158, 0.7898, 0.7633, 0.7367, 0.7091,
        0.6796, 0.6559, 0.6426, 0.6404, 0.6414, 0.6383, 0.6243, 0.5969, 0.5616,
        0.5305, 0.5115, 0.4982, 0.4905, 0.4882, 0.4887], device='cuda:3')
epoch eval loss:
sst: 586.75, nino: 123.15, sc: 48.0222
eval score is not improved for 1 epoch

epoch: 6
batch training loss: 510.81, 23.37, score: 67.8691, ssr ratio: 0.3655
batch training loss: 461.48, 57.28, score: 102.5412, ssr ratio: 0.3455
batch training loss: 549.26, 25.22, score: 104.0237, ssr ratio: 0.3255
batch training loss: 471.70, 13.19, score: 97.0241, ssr ratio: 0.3055
batch training loss: 449.79, 28.80, score: 78.8207, ssr ratio: 0.2855
batch training loss: 498.72, 70.18, score: 99.3909, ssr ratio: 0.2655
batch training loss: 431.39, 33.17, score: 91.7732, ssr ratio: 0.2455
tensor([0.9452, 0.9037, 0.8649, 0.8319, 0.8025, 0.7734, 0.7465, 0.7219, 0.6977,
        0.6721, 0.6517, 0.6406, 0.6384, 0.6374, 0.6316, 0.6157, 0.5876, 0.5532,
        0.5251, 0.5100, 0.5004, 0.4953, 0.4944, 0.4959], device='cuda:3')
epoch eval loss:
sst: 588.49, nino: 121.91, sc: 47.8658
eval score is not improved for 2 epoch

epoch: 7
batch training loss: 439.19, 55.06, score: 46.3198, ssr ratio: 0.2386
batch training loss: 413.41, 46.71, score: 103.4380, ssr ratio: 0.2186
batch training loss: 429.52, 30.30, score: 104.6554, ssr ratio: 0.1986
batch training loss: 520.41, 55.43, score: -11.4483, ssr ratio: 0.1786
batch training loss: 493.42, 23.48, score: 83.5507, ssr ratio: 0.1586
batch training loss: 508.25, 31.75, score: 88.4094, ssr ratio: 0.1386
batch training loss: 499.21, 28.12, score: 104.5597, ssr ratio: 0.1186
tensor([0.9461, 0.9045, 0.8653, 0.8304, 0.7966, 0.7615, 0.7282, 0.6982, 0.6708,
        0.6436, 0.6228, 0.6113, 0.6099, 0.6112, 0.6078, 0.5926, 0.5637, 0.5293,
        0.5030, 0.4918, 0.4856, 0.4825, 0.4821, 0.4841], device='cuda:3')
epoch eval loss:
sst: 588.07, nino: 124.17, sc: 45.4010
eval score is not improved for 3 epoch

epoch: 8
batch training loss: 496.26, 21.93, score: 105.8603, ssr ratio: 0.1118
batch training loss: 548.68, 44.99, score: 36.7804, ssr ratio: 0.0918
batch training loss: 568.51, 70.49, score: 75.1724, ssr ratio: 0.0718
batch training loss: 597.75, 55.12, score: 93.3145, ssr ratio: 0.0518
batch training loss: 470.43, 30.98, score: 39.9557, ssr ratio: 0.0318
batch training loss: 562.48, 59.29, score: 82.5690, ssr ratio: 0.0118
batch training loss: 523.59, 19.60, score: 88.1937, ssr ratio: 0.0000
tensor([0.9445, 0.9014, 0.8612, 0.8260, 0.7933, 0.7602, 0.7300, 0.7041, 0.6799,
        0.6552, 0.6366, 0.6279, 0.6287, 0.6313, 0.6284, 0.6142, 0.5869, 0.5536,
        0.5285, 0.5177, 0.5112, 0.5078, 0.5081, 0.5102], device='cuda:3')
epoch eval loss:
sst: 590.79, nino: 122.36, sc: 47.7499
eval score is not improved for 4 epoch

epoch: 9
batch training loss: 514.82, 92.23, score: 98.2522, ssr ratio: 0.0000
batch training loss: 550.10, 41.09, score: 90.5568, ssr ratio: 0.0000
batch training loss: 494.87, 38.80, score: 96.1427, ssr ratio: 0.0000
batch training loss: 559.40, 47.95, score: 102.6211, ssr ratio: 0.0000
batch training loss: 546.35, 50.75, score: 80.2026, ssr ratio: 0.0000
batch training loss: 525.46, 23.71, score: 97.3293, ssr ratio: 0.0000
batch training loss: 519.72, 53.40, score: 100.3543, ssr ratio: 0.0000
tensor([0.9467, 0.9034, 0.8611, 0.8240, 0.7896, 0.7550, 0.7230, 0.6948, 0.6688,
        0.6435, 0.6256, 0.6182, 0.6205, 0.6240, 0.6210, 0.6059, 0.5773, 0.5425,
        0.5169, 0.5066, 0.5012, 0.4992, 0.5013, 0.5052], device='cuda:3')
epoch eval loss:
sst: 592.41, nino: 124.19, sc: 46.5480
eval score is not improved for 5 epoch
early stopping reached, best score is 48.070355

----- training finished -----

processing test set
(395, 38, 24, 48, 1, 4)
(395, 38, 24, 48, 4)
(395, 38, 3)
predData.shape= (395, 38, 2, 24, 48)
{'sst': (395, 38, 24, 48, 6), 'nino target': (395, 38, 3)}
loading test dataloader
testing...
tensor([0.9460, 0.9062, 0.8716, 0.8438, 0.8194, 0.7931, 0.7653, 0.7367, 0.7068,
        0.6749, 0.6492, 0.6349, 0.6325, 0.6338, 0.6314, 0.6182, 0.5917, 0.5578,
        0.5302, 0.5163, 0.5085, 0.5059, 0.5079, 0.5106], device='cuda:3')
test loss:
 sst: 586.15, nino: 124.27, score: 48.0704
