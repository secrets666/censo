nohup: 忽略输入
{'n_cpu': 0, 'device': device(type='cuda', index=0), 'batch_size_test': 40, 'batch_size': 2, 'lr': 0.001, 'weight_decay': 0, 'display_interval': 250, 'num_epochs': 50, 'early_stopping': True, 'patience': 10, 'gradient_clipping': True, 'clipping_threshold': 1.0, 'input_dim': 8, 'output_dim': 2, 'input_length': 12, 'output_length': 24, 'input_gap': 1, 'pred_shift': 24, 'model_i': 0, 'kernel_size': (3, 3), 'bias': True, 'hidden_dim_1': (128, 128, 128, 128), 'd_attn_1': 64, 'ssr_decay_rate': 8e-05, 'hidden_dim_2': (32, 32, 32, 32), 'd_attn_2': 16, 'hidden_dim_3': (32, 32, 32, 32), 'd_attn_3': 16, 'hidden_dim_4': (32, 32, 32, 32), 'd_attn_4': 16, 'hidden_dim_5': (32, 32, 32, 32), 'd_attn_5': 16, 'use_hc': 1, 'time': 'hybrid', 'save_last': 0}

reading data
(1692, 24, 48, 21, 4) (432, 24, 48, 1, 4)
(1692, 21, 3) (432, 1, 3)
processing training set
(128, 38, 24, 48, 21, 4)
(2688, 38, 24, 48, 4)
(2688, 38, 3)
predData.shape= (2688, 38, 2, 24, 48)
{'sst': (2688, 38, 24, 48, 6), 'nino target': (2688, 38, 3)}
processing eval set
(395, 38, 24, 48, 1, 4)
(395, 38, 24, 48, 4)
(395, 38, 3)
predData.shape= (395, 38, 2, 24, 48)
{'sst': (395, 38, 24, 48, 6), 'nino target': (395, 38, 3)}
Total params num: 7040258
*****************Finish Parameter****************
loading train dataloader
loading eval dataloader

epoch: 1
batch training loss: 941.05, 161.93, score: -39.2609, ssr ratio: 0.9999
batch training loss: 502.66, 22.75, score: 105.6882, ssr ratio: 0.9799
batch training loss: 402.12, 19.38, score: 87.8478, ssr ratio: 0.9599
batch training loss: 374.68, 24.63, score: 72.5073, ssr ratio: 0.9399
batch training loss: 364.51, 25.20, score: 94.5769, ssr ratio: 0.9199
batch training loss: 429.18, 28.35, score: 88.6001, ssr ratio: 0.8999
tensor([0.9320, 0.8819, 0.8404, 0.8120, 0.7941, 0.7799, 0.7669, 0.7538, 0.7383,
        0.7176, 0.6968, 0.6819, 0.6746, 0.6704, 0.6633, 0.6478, 0.6215, 0.5892,
        0.5610, 0.5432, 0.5300, 0.5218, 0.5182, 0.5158], device='cuda:0')
epoch eval loss:
sst: 658.29, nino: 122.56, sc: 51.2018
eval score is improved from -inf to 51.20178, saving model

epoch: 2
batch training loss: 406.69, 24.69, score: 93.8688, ssr ratio: 0.8924
batch training loss: 391.57, 19.39, score: 106.2917, ssr ratio: 0.8724
batch training loss: 439.22, 38.18, score: 87.1330, ssr ratio: 0.8524
batch training loss: 411.35, 20.20, score: 94.9537, ssr ratio: 0.8324
batch training loss: 455.86, 17.45, score: 105.8823, ssr ratio: 0.8124
batch training loss: 405.47, 19.50, score: 77.6864, ssr ratio: 0.7924
tensor([0.9209, 0.8668, 0.8175, 0.7764, 0.7422, 0.7109, 0.6818, 0.6550, 0.6295,
        0.6019, 0.5770, 0.5599, 0.5543, 0.5536, 0.5483, 0.5341, 0.5108, 0.4833,
        0.4641, 0.4589, 0.4578, 0.4584, 0.4629, 0.4676], device='cuda:0')
epoch eval loss:
sst: 597.15, nino: 129.96, sc: 39.7858
Epoch 00002: reducing learning rate of group 0 to 3.0000e-04.
eval score is not improved for 1 epoch

epoch: 3
batch training loss: 369.45, 25.22, score: 99.4686, ssr ratio: 0.7849
batch training loss: 383.14, 16.03, score: 106.8309, ssr ratio: 0.7649
batch training loss: 471.42, 15.22, score: 95.7249, ssr ratio: 0.7449
batch training loss: 412.84, 11.39, score: 102.8569, ssr ratio: 0.7249
batch training loss: 440.32, 24.94, score: 85.6477, ssr ratio: 0.7049
batch training loss: 466.13, 29.76, score: 101.0675, ssr ratio: 0.6849
tensor([0.9383, 0.8900, 0.8445, 0.8066, 0.7752, 0.7465, 0.7206, 0.6980, 0.6772,
        0.6544, 0.6342, 0.6223, 0.6205, 0.6225, 0.6212, 0.6105, 0.5878, 0.5571,
        0.5304, 0.5150, 0.5047, 0.4988, 0.4979, 0.4995], device='cuda:0')
epoch eval loss:
sst: 587.61, nino: 123.30, sc: 46.8971
Epoch 00003: reducing learning rate of group 0 to 1.0000e-04.
eval score is not improved for 2 epoch

epoch: 4
batch training loss: 374.25, 22.45, score: 99.9327, ssr ratio: 0.6774
batch training loss: 377.81, 16.45, score: 99.8733, ssr ratio: 0.6574
batch training loss: 474.50, 26.87, score: 88.8954, ssr ratio: 0.6374
batch training loss: 479.93, 17.64, score: 89.4154, ssr ratio: 0.6174
batch training loss: 460.92, 17.08, score: 106.5323, ssr ratio: 0.5974
batch training loss: 381.58, 30.61, score: 93.8848, ssr ratio: 0.5774
tensor([0.9396, 0.8930, 0.8487, 0.8095, 0.7742, 0.7413, 0.7127, 0.6889, 0.6674,
        0.6444, 0.6247, 0.6131, 0.6111, 0.6111, 0.6057, 0.5896, 0.5612, 0.5260,
        0.4962, 0.4792, 0.4683, 0.4616, 0.4598, 0.4620], device='cuda:0')
epoch eval loss:
sst: 594.47, nino: 130.43, sc: 43.5185
eval score is not improved for 3 epoch

epoch: 5
batch training loss: 497.98, 21.17, score: 86.1029, ssr ratio: 0.5698
batch training loss: 394.09, 36.38, score: 103.6430, ssr ratio: 0.5498
batch training loss: 381.82, 33.42, score: 60.3066, ssr ratio: 0.5298
batch training loss: 385.94, 27.03, score: 94.8253, ssr ratio: 0.5098
batch training loss: 519.27, 16.23, score: 106.3915, ssr ratio: 0.4898
batch training loss: 474.55, 28.57, score: 88.9320, ssr ratio: 0.4698
tensor([0.9430, 0.8976, 0.8532, 0.8139, 0.7788, 0.7458, 0.7160, 0.6902, 0.6658,
        0.6391, 0.6156, 0.5998, 0.5936, 0.5898, 0.5819, 0.5647, 0.5354, 0.4994,
        0.4699, 0.4539, 0.4433, 0.4356, 0.4317, 0.4300], device='cuda:0')
epoch eval loss:
sst: 587.85, nino: 127.75, sc: 41.6909
eval score is not improved for 4 epoch

epoch: 6
batch training loss: 440.36, 45.10, score: 102.8465, ssr ratio: 0.4623
batch training loss: 499.02, 25.87, score: 92.8819, ssr ratio: 0.4423
batch training loss: 444.04, 29.84, score: 99.6802, ssr ratio: 0.4223
batch training loss: 441.80, 24.26, score: 56.4314, ssr ratio: 0.4023
batch training loss: 526.33, 30.46, score: 92.6546, ssr ratio: 0.3823
batch training loss: 562.96, 34.51, score: 104.0892, ssr ratio: 0.3623
tensor([0.9398, 0.8933, 0.8489, 0.8103, 0.7763, 0.7445, 0.7169, 0.6939, 0.6726,
        0.6496, 0.6307, 0.6209, 0.6220, 0.6261, 0.6255, 0.6138, 0.5890, 0.5570,
        0.5307, 0.5164, 0.5062, 0.4997, 0.4985, 0.5005], device='cuda:0')
epoch eval loss:
sst: 586.04, nino: 123.52, sc: 47.0278
eval score is not improved for 5 epoch

epoch: 7
batch training loss: 443.73, 20.05, score: 94.3055, ssr ratio: 0.3548
batch training loss: 525.91, 36.42, score: 75.6236, ssr ratio: 0.3348
batch training loss: 513.86, 48.69, score: 102.8975, ssr ratio: 0.3148
batch training loss: 423.33, 37.41, score: -13.8081, ssr ratio: 0.2948
batch training loss: 496.68, 26.42, score: 105.0517, ssr ratio: 0.2748
batch training loss: 530.06, 27.06, score: 56.6810, ssr ratio: 0.2548
tensor([0.9406, 0.8944, 0.8502, 0.8113, 0.7764, 0.7434, 0.7150, 0.6917, 0.6712,
        0.6499, 0.6333, 0.6254, 0.6274, 0.6316, 0.6307, 0.6184, 0.5935, 0.5620,
        0.5363, 0.5228, 0.5138, 0.5086, 0.5082, 0.5110], device='cuda:0')
epoch eval loss:
sst: 589.41, nino: 122.01, sc: 47.7548
eval score is not improved for 6 epoch

epoch: 8
batch training loss: 474.59, 29.12, score: 104.0981, ssr ratio: 0.2473
batch training loss: 458.78, 38.62, score: 102.6346, ssr ratio: 0.2273
batch training loss: 435.97, 39.56, score: 104.0675, ssr ratio: 0.2073
batch training loss: 503.41, 24.25, score: 105.9365, ssr ratio: 0.1873
batch training loss: 563.10, 53.06, score: 23.4715, ssr ratio: 0.1673
batch training loss: 498.80, 63.57, score: 99.7431, ssr ratio: 0.1473
tensor([0.9365, 0.8886, 0.8425, 0.8023, 0.7667, 0.7337, 0.7060, 0.6843, 0.6654,
        0.6454, 0.6301, 0.6234, 0.6264, 0.6302, 0.6275, 0.6135, 0.5869, 0.5543,
        0.5286, 0.5155, 0.5066, 0.5015, 0.5015, 0.5047], device='cuda:0')
epoch eval loss:
sst: 588.26, nino: 122.89, sc: 46.9713
eval score is not improved for 7 epoch

epoch: 9
batch training loss: 482.26, 38.23, score: 87.1421, ssr ratio: 0.1398
batch training loss: 462.43, 28.89, score: 104.7157, ssr ratio: 0.1198
batch training loss: 547.37, 89.49, score: 28.3223, ssr ratio: 0.0998
batch training loss: 488.00, 38.53, score: 65.1931, ssr ratio: 0.0798
batch training loss: 574.12, 45.92, score: 103.2710, ssr ratio: 0.0598
batch training loss: 508.97, 45.20, score: 96.0631, ssr ratio: 0.0398
tensor([0.9409, 0.8961, 0.8525, 0.8140, 0.7786, 0.7446, 0.7156, 0.6920, 0.6713,
        0.6499, 0.6338, 0.6265, 0.6286, 0.6319, 0.6290, 0.6137, 0.5858, 0.5529,
        0.5279, 0.5164, 0.5101, 0.5081, 0.5108, 0.5161], device='cuda:0')
epoch eval loss:
sst: 589.91, nino: 122.42, sc: 47.5361
eval score is not improved for 8 epoch

epoch: 10
batch training loss: 547.81, 25.63, score: 85.9130, ssr ratio: 0.0322
batch training loss: 517.71, 40.57, score: 101.0325, ssr ratio: 0.0122
batch training loss: 537.56, 21.08, score: 86.3604, ssr ratio: 0.0000
batch training loss: 518.85, 106.79, score: 63.5210, ssr ratio: 0.0000
batch training loss: 554.84, 50.04, score: 102.9262, ssr ratio: 0.0000
batch training loss: 601.12, 33.77, score: 86.8766, ssr ratio: 0.0000
tensor([0.9409, 0.8933, 0.8458, 0.8030, 0.7634, 0.7254, 0.6935, 0.6681, 0.6470,
        0.6270, 0.6136, 0.6094, 0.6143, 0.6202, 0.6193, 0.6059, 0.5790, 0.5456,
        0.5196, 0.5075, 0.5004, 0.4976, 0.4998, 0.5047], device='cuda:0')
epoch eval loss:
sst: 589.67, nino: 123.40, sc: 46.0363
eval score is not improved for 9 epoch

epoch: 11
batch training loss: 550.87, 40.24, score: 97.5513, ssr ratio: 0.0000
batch training loss: 568.26, 62.64, score: 75.0004, ssr ratio: 0.0000
batch training loss: 517.42, 68.92, score: 28.5880, ssr ratio: 0.0000
batch training loss: 578.21, 98.44, score: 95.7711, ssr ratio: 0.0000
batch training loss: 517.57, 58.13, score: -14.7307, ssr ratio: 0.0000
batch training loss: 555.14, 46.21, score: 53.6188, ssr ratio: 0.0000
tensor([0.9414, 0.8979, 0.8562, 0.8195, 0.7845, 0.7494, 0.7178, 0.6907, 0.6657,
        0.6402, 0.6208, 0.6123, 0.6148, 0.6193, 0.6163, 0.5997, 0.5690, 0.5327,
        0.5054, 0.4933, 0.4868, 0.4847, 0.4877, 0.4938], device='cuda:0')
epoch eval loss:
sst: 592.27, nino: 125.90, sc: 45.3723
eval score is not improved for 10 epoch
early stopping reached, best score is 51.201779

----- training finished -----

processing test set
(395, 38, 24, 48, 1, 4)
(395, 38, 24, 48, 4)
(395, 38, 3)
predData.shape= (395, 38, 2, 24, 48)
{'sst': (395, 38, 24, 48, 6), 'nino target': (395, 38, 3)}
loading test dataloader
Traceback (most recent call last):
  File "trainer.py", line 264, in <module>
    trainer.network.load_state_dict(chk['net'])
  File "/home/ruichuang/anaconda3/envs/AGCRN_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1604, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for SAConvLSTM:
	size mismatch for layers.0.sa.conv_h.weight: copying a param with shape torch.Size([96, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 128, 1, 1]).
	size mismatch for layers.0.sa.conv_h.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for layers.0.sa.conv_m.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).
	size mismatch for layers.0.sa.conv_m.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for layers.0.sa.conv_z.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).
	size mismatch for layers.0.sa.conv_z.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for layers.0.sa.conv_output.weight: copying a param with shape torch.Size([384, 160, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 192, 3, 3]).
	size mismatch for layers.1.sa.conv_h.weight: copying a param with shape torch.Size([96, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 128, 1, 1]).
	size mismatch for layers.1.sa.conv_h.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for layers.1.sa.conv_m.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).
	size mismatch for layers.1.sa.conv_m.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for layers.1.sa.conv_z.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).
	size mismatch for layers.1.sa.conv_z.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for layers.1.sa.conv_output.weight: copying a param with shape torch.Size([384, 160, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 192, 3, 3]).
	size mismatch for layers.2.sa.conv_h.weight: copying a param with shape torch.Size([96, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 128, 1, 1]).
	size mismatch for layers.2.sa.conv_h.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for layers.2.sa.conv_m.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).
	size mismatch for layers.2.sa.conv_m.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for layers.2.sa.conv_z.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).
	size mismatch for layers.2.sa.conv_z.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for layers.2.sa.conv_output.weight: copying a param with shape torch.Size([384, 160, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 192, 3, 3]).
	size mismatch for layers.3.sa.conv_h.weight: copying a param with shape torch.Size([96, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 128, 1, 1]).
	size mismatch for layers.3.sa.conv_h.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for layers.3.sa.conv_m.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).
	size mismatch for layers.3.sa.conv_m.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for layers.3.sa.conv_z.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).
	size mismatch for layers.3.sa.conv_z.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for layers.3.sa.conv_output.weight: copying a param with shape torch.Size([384, 160, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 192, 3, 3]).
